{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system using matrix factorization techniques\n",
    "\n",
    "In this project recommendation systems using matrix factorization techniques are analyzed. An item based collaborative filtering model is also built in order to compare the performance of the systems. \n",
    "\n",
    "Following matrix factorization techniques are explored in this project\n",
    "- Singular Value Decomposition\n",
    "- Alternating Least Square (ALS) \n",
    "     - ALS using package nifma\n",
    "     - ALS using a coded function \n",
    "- Matrix Factorization using Gradient Descent(GD) (using tensorflow for GD)\n",
    "     - Matrix factors using GD\n",
    "     - Matrix factors using GD with weighted Errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphlab as gl\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (14,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set\n",
    "The movie lense (100k) dataset is used for this project. The data set contains 100k rating for 1682 movies from 943 users. \n",
    "\n",
    "Citation for Data Set  \n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets:\n",
    "History and Context. ACM Transactions on Interactive Intelligent\n",
    "Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.\n",
    "DOI=http://dx.doi.org/10.1145/2827872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read dataset using panda\n",
    "rating = pd.read_csv(\"../data/u.data\",sep=\"\\t\",usecols=[0,1,2],names=[\"uid\",\"movie_id\",\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  movie_id  rating\n",
       "0  196       242       3\n",
       "1  186       302       3\n",
       "2   22       377       1\n",
       "3  244        51       2\n",
       "4  166       346       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "The movie rating is provided in long format. Let's convert it to wide format in order to perform dimension reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Long to wide\n",
    "ratingw=rating.pivot_table(index=\"uid\",columns=\"movie_id\",values=\"rating\")\n",
    "ratingw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction\n",
    "The dataset provided is large and sparse. In order to build the recommendation engine without incurring too much of computing cost the data dimension needs to be reduced. For this project top 1000 movies (in terms of number of ratings, not by scale of rating) are considered. \n",
    "In order to remove user bias, the rating provided by a user is divided by mean user rating. The nifma package requires a non negative matrix to compute ALS. Hence the data is centered around 1 instead of 0. This method results in non uniform scale between above mean and below mean item. That is the different between a mean rating and a rating that is half of mean is 0.5 but difference between mean rating and twice mean rating is 1. But, this didn't affect the performance of the matrix based factorization methods. But, I tried this technique on the music data set (not detailed on this notebook) and it seemed to improve the performance (almost resulted in double precision). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>181</th>\n",
       "      <th>258</th>\n",
       "      <th>174</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.361229</td>\n",
       "      <td>1.361229</td>\n",
       "      <td>1.361229</td>\n",
       "      <td>1.361229</td>\n",
       "      <td>1.361229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.327434</td>\n",
       "      <td>1.327434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395973</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id       50        100       181       258       174\n",
       "uid                                                       \n",
       "1         1.361229  1.361229  1.361229  1.361229  1.361229\n",
       "2         1.327434  1.327434       NaN  0.796460       NaN\n",
       "3              NaN       NaN  1.395973  0.697987       NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rat=ratingw.iloc[:,np.argsort(-ratingw.sum(axis=0))].iloc[:,0:1000]\n",
    "top_rat=top_rat.div(top_rat.mean(axis=1),axis=0) #.div(top_rat.std(axis=1),axis=0)\n",
    "top_rat.iloc[0:3,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pick users who have listened to at least 15 movies\n",
    "top_rat=top_rat[top_rat.count(axis=1)>15]\n",
    "top_rat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert back to long format\n",
    "top_ratl=top_rat.stack().reset_index()\n",
    "top_ratl.columns=[\"uid\",\"movie_id\",\"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test and train data\n",
    "Used graplab package to split data for item based collaborative filtering. For matrix factorization technique 20% of the ratings are randomly selected and removed from training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "rating_sf=gl.SFrame(top_ratl)\n",
    "train_sf, test_sf = gl.recommender.util.random_split_by_user(rating_sf,user_id='uid', item_id='movie_id',\n",
    "                            item_test_proportion=0.4, random_seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Rating 95978\n",
      "Rating to be used for matrix factorization 57449\n"
     ]
    }
   ],
   "source": [
    "#Create a training dataset by removing 20% of available rating\n",
    "ratings_partial= top_rat.applymap(lambda x: x if np.random.random(1)<= .6 else None)\n",
    "print \"Available Rating\",np.sum(~np.isnan(top_rat.as_matrix()))\n",
    "print \"Rating to be used for matrix factorization\",np.sum(~np.isnan(ratings_partial.as_matrix()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item based collaborative filtering as benchmark\n",
    "In order to get idea about performance of the matrix factorization methods, a item based collaborative model is built. The performance of the item based collaboration model is used as benchmark to evaluate matrix factorization techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Build IBCF model using graphlab - using cosine similarity\n",
    "ibcm=gl.item_similarity_recommender.create(train_sf, user_id=\"uid\",\n",
    "                                           item_id=\"movie_id\",target=\"rating\",\n",
    "                                           similarity_type='cosine',only_top_k=15)\n",
    "#Make prediction\n",
    "ibcm.predict(test_sf)\n",
    "ibcm_reco=ibcm.recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBCF - Prediction RMSE 1.02671782222\n",
      "IBCF - Precision: 0.438918345705\n"
     ]
    }
   ],
   "source": [
    "ib_pr_rec=gl.recommender.util.precision_recall_by_user(test_sf,ibcm_reco)\n",
    "ib_pr_rec_df=ib_pr_rec.to_dataframe()\n",
    "print \"IBCF - Prediction RMSE\", ibcm.evaluate_rmse(test_sf,target='rating')['rmse_overall']\n",
    "print \"IBCF - Precision:\",ib_pr_rec_df.precision.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility function for recommender using Matrix Factorization  \n",
    "\n",
    "Function to get top n rating from the completed matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topn(rating,n=10):\n",
    "    top_nrat=np.apply_along_axis(lambda row:np.argsort(-row)[:n],axis=1,arr=rating)\n",
    "    return top_nrat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RMSE and Precision when actual, training (i.e partial ratings) and filled matrices are provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_matrix_fill(actual,partial,filled,nreco=10):\n",
    "    \n",
    "    #Keep only new rating (that is remove rating present in training)\n",
    "    test=np.isnan(partial) & ~np.isnan(actual)\n",
    "    filled_new=np.copy(filled)\n",
    "    filled_new[~np.isnan(partial)]=None\n",
    "\n",
    "    rmse = np.sqrt(np.nanmean(np.square(filled[test] - actual[test])))\n",
    "    topn=get_topn(filled_new,nreco)\n",
    "    nuser,nrat=topn.shape\n",
    "    pos_rat=0.0\n",
    "    for i in range(nuser):\n",
    "        pos_rat += np.nansum(actual[i,topn[i,]]>0)\n",
    "    #print pos_rat\n",
    "    precision = pos_rat/topn.size\n",
    "    return((rmse,precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS using nimfa package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nimfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U Matrix Shape (943, 10)\n",
      "V Matrix Shape (10, 1000)\n"
     ]
    }
   ],
   "source": [
    "lsnmf = nimfa.Lsnmf(ratings_partial.fillna(0).as_matrix(), max_iter=100, rank=10)\n",
    "lsnmf_fit = lsnmf()\n",
    "\n",
    "u_nifma = lsnmf_fit.basis()\n",
    "v_nifma = lsnmf_fit.coef()\n",
    "print \"U Matrix Shape\",u_nifma.shape\n",
    "print \"V Matrix Shape\",v_nifma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS-nifma Overall RMSE 0.770356233077\n",
      "ALS-nifma RMSE for predicted values: 0.808311621191\n",
      "ALS-nifma Precision  for predicted values: 0.469141039236\n"
     ]
    }
   ],
   "source": [
    "filled_nifma= np.dot(u_nifma,v_nifma)\n",
    "print \"ALS-nifma Overall RMSE\",np.sqrt(np.nanmean(np.square(filled_nifma-ratings_partial)))\n",
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_nifma)\n",
    "print \"ALS-nifma RMSE for predicted values:\",rmse\n",
    "print \"ALS-nifma Precision  for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_svd,s_svd,v_svd=linalg.svd(ratings_partial.fillna(0),full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to approximate the matrix the top 10 singular values are considered. Then the rating matrix is reconstructed using the 10 singular values, that is only considering most informative factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Overall RMSE 0.754590094887\n",
      "SVD RMSE for predicted values: 0.805397310962\n",
      "SVD Precision  for predicted values: 0.490774125133\n"
     ]
    }
   ],
   "source": [
    "s_select=s_svd.copy()\n",
    "s_select[10:]=0\n",
    "filled_svd= np.dot(np.dot(u_svd,np.diag(s_select)),v_svd)\n",
    "print \"SVD Overall RMSE\",np.sqrt(np.nanmean(np.square(filled_svd-ratings_partial)))\n",
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_svd)\n",
    "print \"SVD RMSE for predicted values:\",rmse\n",
    "print \"SVD Precision  for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD based method performed slightly better than ALS(from nifma package). Let's try ALS factorization with some regularization. \n",
    "\n",
    "### ALS - Function\n",
    "\n",
    "The below function is based on the function provided in https://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def als(ratings,reg=0.1,ncols=10,iterations=100):\n",
    "    errors=pd.Series(np.zeros(100))\n",
    "    m,n = ratings.shape\n",
    "    u = 5 * np.random.rand(m,ncols)  \n",
    "    v = 5 * np.random.rand(ncols, n) \n",
    "    for i in range(iterations):\n",
    "        u = np.linalg.solve(np.dot(v, v.T) + reg * np.diag([1]*ncols), \n",
    "                            np.dot(v, ratings.T)).T\n",
    "        v = np.linalg.solve(np.dot(u.T, u) + reg * np.diag([1]*ncols),\n",
    "                            np.dot(u.T, ratings))\n",
    "        ratings_approx = np.dot(u, v)\n",
    "        errors.set_value(i,np.sqrt(np.nanmean(np.square(ratings-ratings_approx))))\n",
    "    return((u,v,errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute matrix factor using alternating least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d8809f8d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAJZCAYAAABsuDCzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3df44ef690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_u,als_v,errors=als(ratings_partial.fillna(0).as_matrix(),ncols=10,iterations=100) \n",
    "errors.plot(title=\"RMSE - 10 Factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Overall RMSE 0.755844660453\n",
      "ALS RMSE for predicted values: 0.80644976386\n",
      "ALS Precision for predicted values: 0.490243902439\n"
     ]
    }
   ],
   "source": [
    "filled_als = np.dot(als_u,als_v)\n",
    "print \"ALS Overall RMSE\",np.sqrt(np.nanmean(np.square(filled_als-ratings_partial)))\n",
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_als)\n",
    "print \"ALS RMSE for predicted values:\",rmse\n",
    "print \"ALS Precision for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix decomposition using ALS regularized provides precision rate and RMSE comparable to SVD. Let's increase the factor from 10 to 15 and check how it changes the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d8808ae90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzwAAAJZCAYAAABsuDCzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGC0BB4AAGC0/n/9iXprj/atPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3d60254250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_u,als_v,errors=als(ratings_partial.fillna(0).as_matrix(),ncols=15,iterations=100) \n",
    "errors.plot(title=\"RMSE - 15 factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Overall RMSE 0.732361232859\n",
      "ALS RMSE for predicted values: 0.814608485878\n",
      "ALS Precision  for predicted values: 0.481548250265\n"
     ]
    }
   ],
   "source": [
    "filled_als = np.dot(als_u,als_v)\n",
    "print \"ALS Overall RMSE\",np.sqrt(np.nanmean(np.square(filled_als-ratings_partial)))\n",
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_als)\n",
    "print \"ALS RMSE for predicted values:\",rmse\n",
    "print \"ALS Precision  for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the overall RMSE reduced for 15 factors compared to 10 factors, the prediction RMSE and prediction precision slightly dropped which indicates overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix factorization using Gradient Descent  \n",
    "Gradient Descent could be used to iteratively approximate the rating matrix as a product of two smaller matrices. By constructing the matrix factorization as optimization problem (i.e reducing error between original matrix and the product of factors). I used tensorflow to solve the optimization and come up with matrix factors. I tried two methods\n",
    "- Reduce total squared error between Original matrix and Product of factors (Errors are not Weighted)\n",
    "- Reduce total squared error between Original matrix and Product of factors where the errors are weighted based on wheather rating is available or not\n",
    "\n",
    "#### Non weighted Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#Rating Matrix\n",
    "r = tf.placeholder(tf.float32,[943,1000])\n",
    "#U matrix\n",
    "u_grad = tf.Variable(tf.random_normal([943,10],stddev=1))\n",
    "#V matrix\n",
    "v_grad = tf.Variable(tf.random_normal([10,1000],stddev=1))\n",
    "# UV\n",
    "y = tf.matmul(u_grad, v_grad)\n",
    "#Total Error\n",
    "loss = tf.reduce_sum(tf.square(r - y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.00965e+06\n",
      "loss: 62203.7\n",
      "loss: 52872.5\n",
      "loss: 50273.2\n",
      "loss: 49937.6\n",
      "loss: 49646.7\n",
      "loss: 49246.4\n",
      "loss: 48737.6\n",
      "loss: 48192.1\n",
      "loss: 47703.4\n"
     ]
    }
   ],
   "source": [
    "#Minimize total error\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "curr_u, curr_v, curr_loss = sess.run([u_grad, v_grad, loss], {r: ratings_partial.fillna(0)})\n",
    "for i in range(1000):\n",
    "    sess.run(train,{r:ratings_partial.fillna(0)})\n",
    "    curr_u, curr_v, curr_loss = sess.run([u_grad, v_grad, loss], {r: ratings_partial.fillna(0)})\n",
    "    if i % 100 == 0: print(\"loss: %s\" % (curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factors using GD - Overall RMSE 0.814093726878\n"
     ]
    }
   ],
   "source": [
    "filled_grad = np.dot(curr_u,curr_v)\n",
    "print \"Matrix factors using GD - Overall RMSE\",np.sqrt(np.nanmean(np.square(filled_grad-ratings_partial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factors using GD - MSE for predicted values: 0.840040411033\n",
      "Matrix factors using GD - Precision  for predicted values: 0.397985153765\n"
     ]
    }
   ],
   "source": [
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_grad)\n",
    "print \"Matrix factors using GD - MSE for predicted values:\",rmse\n",
    "print \"Matrix factors using GD - Precision  for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the Gradient descent is lower than ALS or SVD based matrix factorization methods.\n",
    "\n",
    "#### Weighted Errors\n",
    "I tried to reduce error between the matrices considering entries where rating is present. That gave smallest RMSE for training (less than 0.3 ), but the precision for prediction was bad (predicted precision was less than 10% and prediction RMSE was about 0.53).  \n",
    "\n",
    "Below weight provided optimal solution\n",
    "- Entries where rating is available - Weight of 6.5\n",
    "- Entries where rating is not available - Weight of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Error weights\n",
    "error_weights=ratings_partial.copy()\n",
    "error_weights[~np.isnan(ratings_partial)]=6.5\n",
    "error_weights=error_weights.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.90828e+06\n",
      "loss: 193404.0\n",
      "loss: 171810.0\n",
      "loss: 159038.0\n",
      "loss: 153144.0\n",
      "loss: 150107.0\n",
      "loss: 148245.0\n",
      "loss: 147005.0\n",
      "loss: 146156.0\n",
      "loss: 145567.0\n"
     ]
    }
   ],
   "source": [
    "#Error weight\n",
    "err_w = tf.placeholder(tf.float32,[943,1000])\n",
    "#Loss with weighted error\n",
    "loss = tf.reduce_sum(tf.multiply(tf.square(r - y),err_w))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0001)\n",
    "train = optimizer.minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "curr_u, curr_v, curr_loss = sess.run([u_grad, v_grad, loss], {r: ratings_partial.fillna(0),\n",
    "                                                              err_w:error_weights})\n",
    "#print(\"u: %s v: %s loss: %s\" % (curr_u, curr_v, curr_loss))\n",
    "for i in range(1000):\n",
    "    sess.run(train,{r:ratings_partial.fillna(0),err_w:error_weights})\n",
    "    curr_u, curr_v, curr_loss = sess.run([u_grad, v_grad, loss], {r: ratings_partial.fillna(0),\n",
    "                                                                 err_w:error_weights})\n",
    "    if i % 100 == 0: print(\"loss: %s\" % (curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factors using GD (Weighted Errors) - Overall RMSE 0.45799591781\n"
     ]
    }
   ],
   "source": [
    "filled_gradw = np.dot(curr_u,curr_v)\n",
    "print \"Matrix factors using GD (Weighted Errors) - Overall RMSE\",\\\n",
    "           np.sqrt(np.nanmean(np.square(filled_gradw-ratings_partial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factors using GD (Weighted Errors) - RMSE for predicted values: 0.528243477263\n",
      "Matrix factors using GD (Weighted Errors) - Precision  for predicted values: 0.478154825027\n"
     ]
    }
   ],
   "source": [
    "rmse,precision = eval_matrix_fill(top_rat.as_matrix(),ratings_partial.as_matrix(),filled_gradw)\n",
    "print \"Matrix factors using GD (Weighted Errors) - RMSE for predicted values:\",rmse\n",
    "print \"Matrix factors using GD (Weighted Errors) - Precision  for predicted values:\",precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "For the movielens dataset recommendation system based on matrix factorization technique provided better precision rate compared to item based collaborative filtering. The performance of Singular Value Decomposition and Alternate Least Squares methods are performed pretty much similar. The gradient descent model's performance while no weights for errors were used was lower than ALS/SVD methods.But, I was able to improve the performance of the gradient descent based factorization model by using weighted error (with higher weight for available ratings). The matrix factorization using gradient descent with weighted error provided best RMSE (about 0.52 for predicted values) and comparable prediction precision (about 47%), but the gradient descent model was expensive in terms of computation. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
